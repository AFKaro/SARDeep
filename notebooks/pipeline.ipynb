{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERFS4aAePTs9"
      },
      "source": [
        "#### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXdkj-mJbaP2"
      },
      "outputs": [],
      "source": [
        "drive_dir = \"/content/drive/MyDrive/UNICAP/TCC/research\"\n",
        "work_dir = f\"{drive_dir}/results\"\n",
        "data_dir = f\"{drive_dir}/datasets\"\n",
        "checkpoints_dir = f\"{drive_dir}/checkpoints\"\n",
        "datasets = [\"heridal\"]\n",
        "checkpoints = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuXjtAaqmquE",
        "outputId": "ccfc890f-9d0c-4f1c-ccad-5c4b8f70f971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 25 23:51:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CtvRrKfokBW",
        "outputId": "3f93142e-a613-4165-af04-7af66f5773ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--bs-HT4ZH2G"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws1e0SRCbTxX",
        "outputId": "6c5fcae4-822f-452c-e80a-b5b14e2c254c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil, errno\n",
        "import fileinput\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnVIUiWSQCz-",
        "outputId": "d8d5bdc1-3d96-404e-9cb4-8a07f019f0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SARDeep'...\n",
            "remote: Enumerating objects: 835, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 835 (delta 41), reused 55 (delta 22), pack-reused 742\u001b[K\n",
            "Receiving objects: 100% (835/835), 157.42 KiB | 597.00 KiB/s, done.\n",
            "Resolving deltas: 100% (450/450), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AFKaro/SARDeep.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ps7FA2OVset_",
        "outputId": "46d9668f-fb52-487d-b698-877cf15a7a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optimum[neural-compressor]\n",
            "  Downloading optimum-1.8.6-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum[neural-compressor])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[neural-compressor]) (1.11.1)\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum[neural-compressor])\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum[neural-compressor]) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from optimum[neural-compressor]) (0.15.2+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum[neural-compressor]) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum[neural-compressor]) (1.22.4)\n",
            "Collecting huggingface-hub>=0.8.0 (from optimum[neural-compressor])\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from optimum[neural-compressor])\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum-intel[neural-compressor] (from optimum[neural-compressor])\n",
            "  Downloading optimum-intel-1.8.0.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[neural-compressor]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[neural-compressor]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[neural-compressor]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[neural-compressor]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[neural-compressor]) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor])\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum[neural-compressor])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[neural-compressor]) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->optimum[neural-compressor])\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[neural-compressor]) (1.5.3)\n",
            "Collecting xxhash (from datasets->optimum[neural-compressor])\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->optimum[neural-compressor])\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets->optimum[neural-compressor])\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets->optimum[neural-compressor])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.10.1)\n",
            "Collecting neural-compressor>=2.1.0 (from optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading neural_compressor-2.1.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.9 (from optimum[neural-compressor])\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting intel-extension-for-pytorch<2.0.0 (from optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading intel_extension_for_pytorch-1.13.100-cp310-cp310-manylinux2014_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.9->optimum[neural-compressor])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.9->optimum[neural-compressor])\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.9->optimum[neural-compressor])\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.9->optimum[neural-compressor])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[neural-compressor]) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[neural-compressor]) (0.40.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[neural-compressor]) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from optimum[neural-compressor])\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->optimum[neural-compressor]) (8.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[neural-compressor]) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[neural-compressor]) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->optimum[neural-compressor])\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->optimum[neural-compressor])\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->optimum[neural-compressor])\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->optimum[neural-compressor])\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->optimum[neural-compressor])\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from intel-extension-for-pytorch<2.0.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.2.2)\n",
            "Collecting schema (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (2.0.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (4.7.0.72)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (0.7.2)\n",
            "Collecting deprecated (from neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor])\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->optimum-intel[neural-compressor]->optimum[neural-compressor]) (23.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[neural-compressor]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[neural-compressor]) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum[neural-compressor]) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (3.7.1)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (0.6.0.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.1.0->optimum-intel[neural-compressor]->optimum[neural-compressor]) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum[neural-compressor]) (2.1.2)\n",
            "Building wheels for collected packages: optimum-intel\n",
            "  Building wheel for optimum-intel (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum-intel: filename=optimum_intel-1.8.0-py3-none-any.whl size=95813 sha256=63616e57379a95b4f3ad03e68b619578b970ccc34d86036e277dc757778d9e0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/66/f1/9dd074c5a21c8eee731c7e06afd654637741b2ffff116c9749\n",
            "Successfully built optimum-intel\n",
            "Installing collected packages: tokenizers, sentencepiece, xxhash, schema, protobuf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, multidict, intel-extension-for-pytorch, humanfriendly, frozenlist, dill, deprecated, async-timeout, yarl, responses, onnx, nvidia-cudnn-cu11, multiprocess, huggingface-hub, coloredlogs, aiosignal, transformers, torch, onnxruntime, aiohttp, torchvision, neural-compressor, datasets, optimum, optimum-intel\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 coloredlogs-15.0.1 datasets-2.12.0 deprecated-1.2.13 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 humanfriendly-10.0 intel-extension-for-pytorch-1.13.100 multidict-6.0.4 multiprocess-0.70.14 neural-compressor-2.1.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 onnx-1.14.0 onnxruntime-1.15.0 optimum-1.8.6 optimum-intel-1.8.0 protobuf-3.20.2 responses-0.18.0 schema-0.7.5 sentencepiece-0.1.99 tokenizers-0.13.3 torch-1.13.1 torchvision-0.14.1 transformers-4.29.2 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: terminaltables\n",
            "Successfully installed terminaltables-3.1.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "/bin/bash: pascal-voc-writer==0.1.4: command not found\n",
            "/bin/bash: sklearn: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install optimum[neural-compressor]\n",
        "!pip install tqdm\n",
        "!pip install scipy\n",
        "!pip install terminaltables\n",
        "!pip install six\n",
        "!pip install pycocotools\n",
        "!pip install tensorboard\n",
        "!pip install opencv-python\n",
        "!pip install python-dotenv\n",
        "!pascal-voc-writer==0.1.4\n",
        "!sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmmfAnntry6Q",
        "outputId": "62d82867-b037-4bc7-995c-5304e2f8bf23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "\u001b[33m\r0% [2 InRelease 47.5 kB/114 kB 42%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [2 InRelease 47.5 kB/114 kB 42%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Wa\u001b[0m\r                                                                               \rHit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\u001b[0m\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "\u001b[33m\r0% [7 InRelease 6,947 B/108 kB 6%] [Waiting for headers] [Connecting to ppa.lau\u001b[0m\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\u001b[33m\r                                                                    \r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to ppa.launchpad.net (185.125.190.52)]\u001b[0m\r                                                                           \rHit:10 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,581 kB]\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,218 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,346 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,202 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,726 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,051 kB]\n",
            "Fetched 12.5 MB in 3s (4,209 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.3-1).\n",
            "libxext6 is already the newest version (2:1.3.4-0ubuntu1).\n",
            "libxrender-dev is already the newest version (1:0.9.10-1).\n",
            "libxrender-dev set to manually installed.\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.11).\n",
            "libglib2.0-0 is already the newest version (2.64.6-1~ubuntu20.04.4).\n",
            "libglib2.0-0 set to manually installed.\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following NEW packages will be installed:\n",
            "  ninja-build\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 107 kB of archives.\n",
            "After this operation, 338 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 ninja-build amd64 1.10.0-1build1 [107 kB]\n",
            "Fetched 107 kB in 0s (1,617 kB/s)\n",
            "Selecting previously unselected package ninja-build.\n",
            "(Reading database ... 122545 files and directories currently installed.)\n",
            "Preparing to unpack .../ninja-build_1.10.0-1build1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.0-1build1) ...\n",
            "Setting up ninja-build (1.10.0-1build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n",
        "!apt clean\n",
        "!rm -rf /var/lib/apt/lists/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKRW0-QLVYhL",
        "outputId": "47d6567c-c38b-4e7a-ca5a-115426a447d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu117, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.2%2Bcu117-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.1%2Bcu117-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu117/torchaudio-0.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Installing collected packages: torchaudio\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.2+cu118\n",
            "    Uninstalling torchaudio-2.0.2+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.2+cu118\n",
            "Successfully installed torchaudio-0.13.1+cu117\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.3)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.3)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Installing collected packages: ordered-set, colorama, model-index, openmim\n",
            "Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13/index.html\n",
            "Collecting mmcv-full==1.7.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/mmcv_full-1.7.0-cp310-cp310-manylinux1_x86_64.whl (46.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv-full==1.7.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.0) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.0) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.0) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.0) (6.0)\n",
            "Collecting yapf (from mmcv-full==1.7.0)\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full==1.7.0) (4.7.0.72)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full==1.7.0) (2.0.1)\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.0 yapf-0.33.0\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 25592, done.\u001b[K\n",
            "remote: Total 25592 (delta 0), reused 0 (delta 0), pack-reused 25592\u001b[K\n",
            "Receiving objects: 100% (25592/25592), 39.49 MiB | 23.96 MiB/s, done.\n",
            "Resolving deltas: 100% (17513/17513), done.\n",
            "/content/SARDeep/src/mmdetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/SARDeep/src/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.22.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet==2.28.2) (3.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==2.28.2) (2.8.2)\n",
            "Installing collected packages: mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.28.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install openmim\n",
        "!pip install mmcv-full==1.7.0 -f https://download.openmmlab.com/mmcv/dist/cu117/torch1.13/index.html\n",
        "!cd /content/SARDeep/src && git clone -b 2.x --single-branch https://github.com/open-mmlab/mmdetection.git\n",
        "%cd /content/SARDeep/src/mmdetection\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vtJJ9d9RDBc-"
      },
      "outputs": [],
      "source": [
        "def copy(src, dst):\n",
        "    if not os.path.isdir(dst):\n",
        "      try:\n",
        "          shutil.copytree(src, dst)\n",
        "      except OSError as exc: # python >2.5\n",
        "          if exc.errno in (errno.ENOTDIR, errno.EINVAL):\n",
        "              shutil.copy(src, dst)\n",
        "          else: raise\n",
        "\n",
        "for dataset in datasets:\n",
        "  copy(f\"{data_dir}/{dataset}\", f\"/content/SARDeep/src/mmdetection/data/{dataset}\")\n",
        "\n",
        "copy(checkpoints_dir, f\"/content/SARDeep/src/infra/checkpoints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-MpHbrraSYDX"
      },
      "outputs": [],
      "source": [
        "for checkpoint in checkpoints:\n",
        "  !python /content/SARDeep/src/infra/scripts/download_weights.py --weights $checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RZ1LvX6Wz6U_"
      },
      "outputs": [],
      "source": [
        "import dotenv\n",
        "import os\n",
        "\n",
        "dotenv_file = dotenv.find_dotenv()\n",
        "dotenv.load_dotenv(dotenv_file)\n",
        "\n",
        "env_vars = (\"CHECKPOINTS_PATH\", \"RESOURCE_PATH\", \"CONFIG_PATH\", \"WORK_DIR\", \n",
        "            \"DATA_ROOT\", \"DEVICE\", \"DATA_PATH\", \"BASE_DIR\")\n",
        "\n",
        "os.environ[\"CHECKPOINTS_PATH\"] = \"../infra/checkpoints\"\n",
        "os.environ[\"RESOURCE_PATH\"] = \"../../resource\"\n",
        "os.environ[\"CONFIG_PATH\"] = \"../../src/infra/configs\"\n",
        "os.environ[\"WORK_DIR\"] = f\"../../../../{work_dir}\"\n",
        "os.environ[\"DATA_ROOT\"] = \"../mmdetection/data\"\n",
        "os.environ[\"DEVICE\"] = \"cuda\"\n",
        "os.environ[\"DATA_PATH\"] = \"/content/drive/MyDrive/UNICAP/TCC/research/datasets\"\n",
        "os.environ[\"BASE_DIR\"] = \"/content/SARDeep/src\"\n",
        "\n",
        "for env in env_vars:\n",
        "  dotenv.set_key(dotenv_file, env, os.environ[env])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EqHtWosOSZju",
        "outputId": "e0478e34-09a1-4fe9-cb81-ebe3a908e39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/UNICAP/TCC/research/datasets sard\n",
            "Classes: ['person']\n"
          ]
        }
      ],
      "source": [
        "!python /content/SARDeep/src/infra/scripts/config_classes.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bdMRsCPmgvsd"
      },
      "outputs": [],
      "source": [
        "def update_config(model_name, train_data, test_data, fold, max_epochs, lr, momentum, interval):\n",
        "  with open(\"/content/SARDeep/resource/pipeline.json\", \"r\") as jsonFile:\n",
        "    data = json.load(jsonFile)\n",
        "  \n",
        "  with open(\"/content/SARDeep/resource/models.json\", \"r\") as jsonFile:\n",
        "    data_models = json.load(jsonFile)\n",
        "\n",
        "  data[\"models\"] = [model_name]\n",
        "  data[\"datasets\"][\"dataset_train\"] = train_data\n",
        "  data[\"datasets\"][\"dataset_test\"] = test_data\n",
        "  data[\"datasets\"][\"fold\"] = f\"fold{fold}\"\n",
        "\n",
        "  data[\"priority_steps\"][0][\"dataset_train\"] = train_data\n",
        "  data[\"priority_steps\"][0][\"dataset_test\"] = test_data\n",
        "\n",
        "  for idx, models in enumerate(data_models[\"models\"]):\n",
        "    if f\"\"\"{models[\"name\"]}{models[\"version\"]}\"\"\" == model_name:\n",
        "      data_models[\"models\"][idx][\"runner\"][\"max_epochs\"] = max_epochs\n",
        "      data_models[\"models\"][idx][\"optimizer\"][\"lr\"] = lr\n",
        "      data_models[\"models\"][idx][\"optimizer\"][\"momentum\"] = momentum\n",
        "      data_models[\"models\"][idx][\"optimizer\"][\"interval\"] = interval\n",
        "  \n",
        "  print(data_models)\n",
        "\n",
        "  with open(\"/content/SARDeep/resource/pipeline.json\", \"w\") as jsonFile:\n",
        "      json.dump(data, jsonFile)\n",
        "  \n",
        "  with open(\"/content/SARDeep/resource/models.json\", \"w\") as jsonFile:\n",
        "      json.dump(data_models, jsonFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg1SmwN4ZEDf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hdkBkM6ZL53"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMMx6UePSpgQ",
        "outputId": "c679b5aa-9aae-4c6b-a210-469ea09e6ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'models': [{'name': 'faster_rcnn', 'version': '', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 60}, 'fine_tune': {'name': 'faster_rcnn_r50_fpn_1x_coco', 'load_from': 'CHECKPOINTS_PATH/faster_rcnn_r50_fpn_1x_coco.pth'}}, {'name': 'yolo', 'version': 'v3', 'optimizer': {'lr': 0.001, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 100}, 'fine_tune': {'name': 'yolov3_d53_fp16_mstrain-608_273e_coco', 'load_from': 'CHECKPOINTS_PATH/yolov3_d53_fp16_mstrain-608_273e_coco.pth'}}, {'name': 'yolo', 'version': 'x', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 30}, 'fine_tune': {'name': 'yolox_x_8x8_300e_coco', 'load_from': 'CHECKPOINTS_PATH/yolox_x_8x8_300e_coco.pth'}}, {'name': 'yolo', 'version': 'x_tiny', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 20}, 'runner': {'max_epochs': 200}, 'fine_tune': {'name': 'yolox_tiny_8x8_300e_coco', 'load_from': 'CHECKPOINTS_PATH/yolox_tiny_8x8_300e_coco.pth'}}, {'name': 'fcos', 'version': '', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 30}, 'fine_tune': {'name': 'fcos_x101_64x4d_fpn_gn-head_mstrain_640-800_2x_coco', 'load_from': 'CHECKPOINTS_PATH/fcos_x101_64x4d_fpn_gn-head_mstrain_640-800_2x_coco.pth'}}, {'name': 'ssd', 'version': '', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 80}, 'fine_tune': {'name': 'ssd512_coco', 'load_from': 'CHECKPOINTS_PATH/ssd512_coco.pth'}}, {'name': 'efficientnet', 'version': '', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 5}, 'runner': {'max_epochs': 30}, 'fine_tune': {'name': 'retinanet_effb3_fpn_crop896_8x4_1x_coco', 'load_from': 'CHECKPOINTS_PATH/retinanet_effb3_fpn_crop896_8x4_1x_coco.pth'}}, {'name': 'foveabox', 'version': '', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 12}, 'runner': {'max_epochs': 24}, 'fine_tune': {'name': 'fovea_align_r101_fpn_gn-head_mstrain_640-800_4x4_2x_coco', 'load_from': 'CHECKPOINTS_PATH/fovea_align_r101_fpn_gn-head_mstrain_640-800_4x4_2x_coco.pth'}}, {'name': 'yolo', 'version': 'f', 'optimizer': {'lr': 0.01, 'momentum': 0.9, 'interval': 12}, 'runner': {'max_epochs': 24}, 'fine_tune': {'name': 'yolof_r50_c5_8x8_1x_coco', 'load_from': 'CHECKPOINTS_PATH/yolof_r50_c5_8x8_1x_coco.pth'}}]}\n"
          ]
        }
      ],
      "source": [
        "model_name = \"yolox_l\" #@param {type:\"string\"}\n",
        "step = \"Train\" #@param [\"All\", \"Train\", \"Quantization\", \"Test\", \"Eval\"]\n",
        "#@markdown ---\n",
        "lr = 0.002 #@param {type:\"number\"}\n",
        "momentum = 0.9 #@param {type:\"number\"}\n",
        "interval = 20 #@param {type:\"integer\"}\n",
        "max_epochs = 100 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "train_data = \"sard\" #@param [\"sard\", \"heridal\", \"seadronesee\"]\n",
        "fold = 1 #@param {type:\"integer\"}\n",
        "test_data = \"sard\" #@param [\"sard\", \"heridal\", \"seadronesee\"]\n",
        "\n",
        "\n",
        "update_config(model_name, train_data, test_data, fold, max_epochs, lr, momentum, interval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf5v2TCNSrcu"
      },
      "outputs": [],
      "source": [
        "!python /content/SARDeep/src/main.py --step $step"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}